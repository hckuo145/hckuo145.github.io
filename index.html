<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Heng-Cheng Kuo</title>
    <style>
        html {
            font-size: 18px;
        }
        body {
            margin-left: 100px;
            margin-right: 100px;
        }
    </style>
    <link rel="stylesheet" href="styles.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
</head>

<body>
    <div class="container">
        <div class="content">
            <img src="profile.jpg" style="float: right; width: 300px; height: 300px; margin-left: 20px;">
            <h1>About Me</h1>
            <p>I am Heng-Cheng Kuo, hold an M.S. in Data Science from National Taiwan University, advised by Prof. <a href="https://speech.ee.ntu.edu.tw/~hylee/index.php" target="_blank">Hung-yi Lee</a> and Prof. <a href="https://bio-asplab.citi.sinica.edu.tw/" target="_blank">Yu Tsao</a>. Prior to that, I received my B.S. degree in EE at National Taiwan University. I worked with Prof. <a href="https://speech.ee.ntu.edu.tw/previous_version/lslNew.htm" target="_blank">Lin-shan Lee</a> at the Speech Processing Lab.</p>
            <p>My research interests include <strong>Speech Editing</strong>, <strong>Anti-Spoofing</strong>, and <strong>Self-Supervised Learning</strong>. I helped organize the ASVspoof5 Challenge by supplying participants with pre-trained self-supervised speech models and co-developed the Speech INfilling Edit (SINE) dataset in collaboration with NVIDIA researchers.</p>
        </div>
    </div>
</body>

<body>
    <div class="container">
        <div class="content">
            <h1>Journal Publications</h1>
            <p><strong>Toward Real-World Voice Disorder Classification</strong>
                <br><u>Heng-Cheng Kuo</u>, Yu-Peng Hsieh, Huan-Hsin Tseng, Chi-Te Wang, Shih-Hau Fang, Yu Tsao
                <br><i>2023 IEEE Transactions on Biomedical Engineering, Vol. 70, No. 10</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://ieeexplore.ieee.org/document/10109168" target="_blank">PDF</a>]</p>
            <p><strong>Domain-adaptive Fall Detection Using Deep Adversarial Training</strong>
                <br>Kai-Chun Liu, Michael Chan, <u>Heng-Cheng Kuo</u>, Chia-Yeh Hsieh, Hsiang-Yun Huang, Chia-Tai Chan, Yu Tsao
                <br><i>2021 IEEE Transactions on Neural Systems and Rehabilitation Engineering, Vol. 29</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://ieeexplore.ieee.org/abstract/document/9456857" target="_blank">PDF</a>]</p>
        </div>
    </div>
</body>

<body>
    <div class="container">
        <div class="content">
            <h1>Conference Publications</h1>
            <p><strong>An Exploration of Mamba for Speech Self-Supervised Models</strong>
                <br>Tzu-Quan Lin*, <u>Heng-Cheng Kuo</u>u*, Tzu-Chieh Wei, Hsi-Chun Cheng, Chun-Wei Chen, Hsien-Fu Hsiao, Yu Tsao, Hung-yi Lee
                <br><i>In Submission</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://arxiv.org/abs/2506.12606" target="_blank">PDF</a>]</p>
            <p><strong>VoiceNoNG: High-Quality Speech Editing Model Without Hallucinations</strong>
                <br>Sung-Feng Huang, Heng-Cheng Kuo, Zhehuai Chen, Xuesong Yang, Pin-Jui Ku, Ante JukiÄ‡, Chao-Han Huck Yang, Yu Tsao, Yu-Chiang Frank Wang,
                <br>Hung-yi Lee, Szu-Wei Fu
                <br><i>2025 IEEE International Conference on Acoustics, Speech and Signal Processing</i></p>
            <p><strong>Detecting The Undetectable: Assessing The Efficacy of Current Spoof Detection Methods against Seamless Speech Edits</strong>
                <br>Sung-Feng Huang, <u>Heng-Cheng Kuo</u>, Zhehuai Chen, Xuesong Yang, Huck Yang, Yu Tsao, Yu-Chiang Frank Wang, Hung-yi Lee, Szu-Wei Fu
                <br><i>2024 IEEE Spoken Language Technology Workshop</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://research.nvidia.com/labs/twn/publication/slt_2024_sine/" target="_blank">PDF</a>]</p>
            <p><strong>Scalable Ensemble-based Detection Method against Adversarial Attacks for Speaker Verification</strong>
                <br>Haibin Wu, <u>Heng-Cheng Kuo</u>, Yu Tsao, Hung-yi Lee
                <br><i>2024 IEEE International Conference on Acoustics, Speech and Signal Processing</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://arxiv.org/abs/2312.08622" target="_blank">PDF</a>]</p>
            <p><strong>Study on the Correlation between Objective Evaluations and Subjective Speech Quality and Intelligibility</strong>
                <br>Hsin-Tien Chiang, Kuo-Hsuan Hung, Szu-Wei Fu, <u>Heng-Cheng Kuo</u>, Ming-Hsueh Tsai, Yu Tsao
                <br><i>2023 Workshop on Automatic Speech Recognition and Understanding</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://arxiv.org/abs/2307.04517" target="_blank">PDF</a>]</p>
            <p><strong>Voice Direction-of-Arrival Conversion</strong>
                <br>I-Chun Chern, Steffi Chern, <u>Heng-Cheng Kuo</u>, Huan-Hsin Tseng, Kuo-Hsuan Hung, Yu Tsao
                <br><i>2023 IEEE International Workshop on Machine Learning for Signal Processing</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://ieeexplore.ieee.org/document/10285936" target="_blank">PDF</a>]</p>
            <p><strong>Partially Fake Audio Detection by Self-attention-based Fake Span Discovery</strong>
                <br>Haibin Wu, <u>Heng-Cheng Kuo</u>, Naijun Zheng, Kuo-Hsuan Hung, Hung-Yi Lee, Yu Tsao, Hsin-Min Wang, Helen Meng
                <br><i>2022 IEEE International Conference on Acoustics, Speech and Signal Processing</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://arxiv.org/abs/2202.06684" target="_blank">PDF</a>]</p>
            <p><strong>Key Generation with Ambient Audio</strong>
                <br>Bo-Rong Chen, Hsin-Tien Chiang, <u>Heng-Cheng Kuo</u>, Yu Tsao, Yih-Chun Hu
                <br><i>2022 IEEE Global Communications Conference</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://ieeexplore.ieee.org/document/10001118" target="_blank">PDF</a>]</p>
            <p><strong>Boosting Objective Scores of a Speech Enhancement Model by MetricGAN Post-processing</strong>
                <br>Szu-Wei Fu, Chien-Feng Liao, Tsun-An Hsieh, Kuo-Hsuan Hung, Syu-Siang Wang, Cheng Yu, <u>Heng-Cheng Kuo</u>, Ryandhimas E. Zezario, You-Jin Li,
                <br>Shang-Yi Chuang, Yen-Ju Lu, Yu Tsao
                <br><i>2020 Asia-Pacific Signal and Information Processing Association Conference</i>
                <br><i class="fas fa-file-pdf"></i>[<a href="https://ieeexplore.ieee.org/document/9306484" target="_blank">PDF</a>]</p>
        </div>
    </div>
</body>


<body>
    <div class="container">
        <div class="content">
            <h1>Awards</h1>
            <p>Won <strong>1st</strong> place in the Multi-Object Tracking with Reidentification track of the <a href="https://macvi.org/workshop/macvi24/challenges/" target="_blank">MaCVi challenge</a> at WaCV 2024.</p>
            <p>Won <strong>2nd</strong> place in the Partially Fake Audio Detection track of the <a href="http://addchallenge.cn/add2022" target="_blank">ADD challenge</a> at ICASSP 2022.</p>
        </div>
    </div>
</body>
</html>
